{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90bf26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617ab15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv('D:/B3_Lokal-Datensatzpaket/CSV/MiD2017_Lokal_Personen.csv', sep=';', usecols = ['H_ID_Lok', 'P_ID', 'P_GEW', 'P_HOCH', 'vpedrad', 'HP_SEX', 'alter_gr', 'taet', 'P_BIL', 'hhgr_gr2', 'oek_status', 'GITTER_500m', 'GITTER_1km', 'GITTER_5km', 'PRAEZISION', 'P_FKARTE', 'P_STKFZ'])\n",
    "#d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fdf3ea-b7ae-4f30-adfc-bf98c7e41441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#edsc stats before data processing\n",
    "#print(d['Raumtyp'].value_counts(normalize=True)) not available before data processing\n",
    "print(d['oek_status'].value_counts(normalize=True))\n",
    "print(d['taet'].value_counts(normalize=True))\n",
    "print(d['hhgr_gr2'].value_counts(normalize=True))\n",
    "print(d['HP_SEX'].value_counts(normalize=True))\n",
    "print(d['P_BIL'].value_counts(normalize=True))\n",
    "print(d['alter_gr'].value_counts(normalize=True))\n",
    "print(d['vpedrad'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f530da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#throw out missing pedelec availability responses; 9= \"no response\", 200 = \"not surveyed\" (mostly children)\n",
    "#throws out ~26%\n",
    "d = d[d.vpedrad != 9]\n",
    "d = d[d.vpedrad != 200]\n",
    "\n",
    "#throw out other missing values\n",
    "#throws out another ~1.5%\n",
    "d = d[d.HP_SEX != 9]\n",
    "d = d[d.alter_gr != 99]\n",
    "d = d[d.taet != 9]\n",
    "d = d[d.P_BIL != 9]\n",
    "d = d[d.PRAEZISION != 9]\n",
    "d = d[d.P_STKFZ != 9]\n",
    "d = d[d.P_FKARTE != 99]\n",
    "\n",
    "#throw out people whose location is not known at least to the 1km-grid cell level\n",
    "#throws out another ~25%\n",
    "d = d.loc[d['GITTER_1km'].str.contains(\"1km\", case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261eb4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove people over 18 who have no eduation level\n",
    "# this is needed because we interacted education level with being over 18; this means we had to disregard P_BIL_1, because there are too few cases of ppl over 18 with no educaiton \n",
    "d = d[~((d['P_BIL'] == 1) & (d['alter_gr'] == 1))]\n",
    "#d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0338d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file containing spatial typology and gradient for every 1km cell\n",
    "cells = pd.read_csv('../1km_Raumtyp_Slope.csv', usecols=['cellname', 'Raumtyp', 'slope'])\n",
    "#cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a5ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the map function to populate the elevar column in gridcells1km\n",
    "\n",
    "#get elevar values for the residential location \n",
    "cells = cells.set_index('cellname')\n",
    "\n",
    "# Add a new column 'elevar' in dataframe 'd'\n",
    "d['elevar'] = 99\n",
    "\n",
    "# Use the map function to populate the elevar column in gridcells1km\n",
    "d['elevar'] = d['GITTER_1km'].map(cells['slope'])\n",
    "\n",
    "#throw out elevar=NaN entries\n",
    "d = d.dropna(subset=['elevar'])\n",
    "\n",
    "d['elevar'] = d['elevar']/100\n",
    "d['elevar'] = d['elevar'].apply(lambda x: round(x, 2))\n",
    "\n",
    "d = d[d['elevar']<15]\n",
    "#d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa350263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the map function to populate the Raumtyp column in gridcells1km\n",
    "\n",
    "# Add a new column 'Raumtyp' in dataframe 'd'\n",
    "d['Raumtyp'] = 99\n",
    "\n",
    "# Use the map function to populate the Raumtyp column in gridcells1km\n",
    "d['Raumtyp'] = d['GITTER_1km'].map(cells['Raumtyp'])\n",
    "\n",
    "#throw out Raumtyp=NaN entries (=non NRW households; reduces dataset to rougly one sixth!)\n",
    "d = d.dropna(subset=['Raumtyp'])\n",
    "\n",
    "#make Raumtyp into int\n",
    "d[['Raumtyp']] = d[['Raumtyp']].astype(int)\n",
    "#d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac58787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptive statistics\n",
    "print(d['Raumtyp'].value_counts(normalize=True))\n",
    "print(d['oek_status'].value_counts(normalize=True))\n",
    "print(d['taet'].value_counts(normalize=True))\n",
    "print(d['hhgr_gr2'].value_counts(normalize=True))\n",
    "print(d['HP_SEX'].value_counts(normalize=True))\n",
    "print(d['P_BIL'].value_counts(normalize=True))\n",
    "print(d['alter_gr'].value_counts(normalize=True))\n",
    "print(d['vpedrad'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(6, 1), dpi=1000)\n",
    "plt.rc('font', family='Arial', size=11)\n",
    "plt.boxplot(d[\"elevar\"], vert=False)\n",
    "plt.yticks([1], ['gradient'])\n",
    "plt.savefig(\"gradient_boxplot.png\", format='png', bbox_inches = 'tight')\n",
    "plt.savefig(\"gradient_boxplot.svg\", format='svg', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab7d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn categorical into dummy variables\n",
    "dummies_Raumtyp = pd.get_dummies(d['Raumtyp'], prefix='Raumtyp').astype(int)\n",
    "dummies_Raumtyp = dummies_Raumtyp.rename(columns=lambda x: x.replace('Raumtyp', ''))\n",
    "dummies_Raumtyp.columns = ['Raumtyp' + str(col) for col in dummies_Raumtyp.columns]\n",
    "d = d.join(dummies_Raumtyp)\n",
    "\n",
    "dummies_alter_gr = pd.get_dummies(d['alter_gr'], prefix='alter_gr').astype(int)\n",
    "dummies_alter_gr = dummies_alter_gr.rename(columns=lambda x: x.replace('alter_gr_', ''))\n",
    "dummies_alter_gr.columns = ['alter_gr_' + str(col) for col in dummies_alter_gr.columns]\n",
    "d = d.join(dummies_alter_gr)\n",
    "\n",
    "dummies_P_BIL = pd.get_dummies(d['P_BIL'], prefix='P_BIL').astype(int)\n",
    "dummies_P_BIL = dummies_P_BIL.rename(columns=lambda x: x.replace('P_BIL_', ''))\n",
    "dummies_P_BIL.columns = ['P_BIL_' + str(col) for col in dummies_P_BIL.columns]\n",
    "d = d.join(dummies_P_BIL)\n",
    "\n",
    "dummies_HP_SEX = pd.get_dummies(d['HP_SEX'], prefix='HP_SEX').astype(int)\n",
    "dummies_HP_SEX = dummies_HP_SEX.rename(columns=lambda x: x.replace('HP_SEX_', ''))\n",
    "dummies_HP_SEX.columns = ['HP_SEX_' + str(col) for col in dummies_HP_SEX.columns]\n",
    "d = d.join(dummies_HP_SEX)\n",
    "\n",
    "dummies_taet = pd.get_dummies(d['taet'], prefix='taet').astype(int)\n",
    "dummies_taet = dummies_taet.rename(columns=lambda x: x.replace('taet_', ''))\n",
    "dummies_taet.columns = ['taet_' + str(col) for col in dummies_taet.columns]\n",
    "d = d.join(dummies_taet)\n",
    "\n",
    "dummies_oek_status = pd.get_dummies(d['oek_status'], prefix='oek_status').astype(int)\n",
    "dummies_oek_status = dummies_oek_status.rename(columns=lambda x: x.replace('oek_status_', ''))\n",
    "dummies_oek_status.columns = ['oek_status_' + str(col) for col in dummies_oek_status.columns]\n",
    "d = d.join(dummies_oek_status)\n",
    "\n",
    "dummies_hhgr_gr2 = pd.get_dummies(d['hhgr_gr2'], prefix='hhgr_gr2').astype(int)\n",
    "dummies_hhgr_gr2 = dummies_hhgr_gr2.rename(columns=lambda x: x.replace('hhgr_gr2_', ''))\n",
    "dummies_hhgr_gr2.columns = ['hhgr_gr2_' + str(col) for col in dummies_hhgr_gr2.columns]\n",
    "d = d.join(dummies_hhgr_gr2)\n",
    "\n",
    "dummies_P_FKARTE = pd.get_dummies(d['P_FKARTE'], prefix='P_FKARTE').astype(int)\n",
    "dummies_P_FKARTE = dummies_P_FKARTE.rename(columns=lambda x: x.replace('P_FKARTE', ''))\n",
    "dummies_P_FKARTE.columns = ['P_FKARTE' + str(col) for col in dummies_P_FKARTE.columns]\n",
    "d = d.join(dummies_P_FKARTE)\n",
    "\n",
    "dummies_P_STKFZ = pd.get_dummies(d['P_STKFZ'], prefix='P_STKFZ').astype(int)\n",
    "dummies_P_STKFZ = dummies_P_STKFZ.rename(columns=lambda x: x.replace('P_STKFZ', ''))\n",
    "dummies_P_STKFZ.columns = ['P_STKFZ' + str(col) for col in dummies_P_STKFZ.columns]\n",
    "d = d.join(dummies_P_STKFZ)\n",
    "\n",
    "# drop the original categorical variables\n",
    "d = d.drop('Raumtyp', axis=1)\n",
    "d = d.drop('HP_SEX', axis=1)\n",
    "d = d.drop('alter_gr', axis=1)\n",
    "d = d.drop('taet', axis=1)\n",
    "d = d.drop('P_BIL', axis=1)\n",
    "d = d.drop('hhgr_gr2', axis=1)\n",
    "d = d.drop('oek_status', axis=1)\n",
    "d = d.drop('P_FKARTE', axis=1)\n",
    "d = d.drop('P_STKFZ', axis=1)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "#d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618ae94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# turn vpedrad into binary dichotomous choice variable\n",
    "d['cbike'] = d['vpedrad'].apply(lambda x: 1 if x in [1, 3] else 0)\n",
    "d['ebike'] = d['vpedrad'].apply(lambda x: 1 if x in [2, 3] else 0)\n",
    "#d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f63b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation matrix between variables\n",
    "# Calculate the correlation matrix\n",
    "columns_to_correlate = ['cbike','ebike','elevar','Raumtyp_11','Raumtyp_12','Raumtyp_21','Raumtyp_22','alter_gr_1','alter_gr_2','alter_gr_3','alter_gr_4','alter_gr_5','alter_gr_6','alter_gr_7','alter_gr_8','P_BIL_1','P_BIL_2','P_BIL_3','P_BIL_4','P_BIL_5','P_BIL_6','HP_SEX_1','HP_SEX_2','taet_1','taet_2','taet_3','taet_4','taet_5','oek_status_1','oek_status_2','oek_status_3','oek_status_4','oek_status_5','hhgr_gr2_1','hhgr_gr2_2','hhgr_gr2_3','hhgr_gr2_4','P_FKARTE_1','P_FKARTE_2','P_FKARTE_3','P_FKARTE_4','P_FKARTE_5','P_FKARTE_6','P_FKARTE_7','P_STKFZ_1','P_STKFZ_3']\n",
    "column_labels = ['c-bike own.','e-bike own.','gradient','spatial typ. 11','spatial typ. 12','spatial typ. 21','spatial typ. 22','age 0-17','age 18-29','age 30-39','age 40-49','age 50-59','age 60-69','age 70-79','age 80+','edu. none','edu. \"V.-/Haupts.\"','edu. \"M. R.\"','edu. \"Abitur\"','edu. university','edu. other','sex male','sex female','occ. employed','occ. education','occ. domestic','occ. retired','occ. other','eco. very low','eco. low','eco. middle','eco. high','eco. very high','hh-size 1','hh-size 2','hh-size 3','hh-size 4+','ticket singletrip','ticket mult. trips','ticket seas. no subs.','ticket seas. with subs.','ticket employer','ticket other','ticket never','car yes','car no']\n",
    "correlation_matrix = d[columns_to_correlate].corr()\n",
    "correlation_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 27))\n",
    "plot = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', annot_kws={\"size\": 10}, cbar_kws={\"orientation\": \"horizontal\"})\n",
    "\n",
    "plt.xticks(ticks=[i+0.5 for i in range(len(columns_to_correlate))], labels=column_labels, rotation=90)\n",
    "plt.yticks(ticks=[i+0.5 for i in range(len(columns_to_correlate))], labels=column_labels, rotation=0)\n",
    "\n",
    "plt.show()\n",
    "fig = plot.get_figure()\n",
    "fig.savefig(\"correlation_matrix.png\", format='png', bbox_inches = 'tight')\n",
    "fig.savefig(\"correlation_matrix.svg\", format='svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3042f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save d\n",
    "#d.to_csv('D:/Processed Data/DE_ownership_input')\n",
    "d_10000 = d.sample(n = 10000)\n",
    "#d_10000.to_csv('D:/Processed Data/DE_ownership_input_10000.csv')\n",
    "d_30000 = d.sample(n = 30000)\n",
    "#d_30000.to_csv('D:/Processed Data/DE_ownership_input_30000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb9b6d-464b-4d01-b870-70066f42c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics for 30k estimation sample\n",
    "print(d_30000['Raumtyp'].value_counts(normalize=True))\n",
    "print(d_30000['oek_status'].value_counts(normalize=True))\n",
    "print(d_30000['taet'].value_counts(normalize=True))\n",
    "print(d_30000['hhgr_gr2'].value_counts(normalize=True))\n",
    "print(d_30000['HP_SEX'].value_counts(normalize=True))\n",
    "print(d_30000['P_BIL'].value_counts(normalize=True))\n",
    "print(d_30000['alter_gr'].value_counts(normalize=True))\n",
    "print(d_30000['vpedrad'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot for spatial distribution of c- and e-bike ownership in NRW (not used in paper)\n",
    "d = pd.read_csv('D:/Processed Data/NRW_ownership_input.csv')\n",
    "\n",
    "bikeownership = d.groupby('GITTER_1km')[['cbike', 'ebike']].mean().reset_index()\n",
    "# Rename columns for clarity\n",
    "bikeownership = bikeownership.rename(columns={'cbike': 'cbike_share', 'ebike': 'ebike_share'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62127bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map cbike \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "bikeownership['x']='0'\n",
    "bikeownership['y']='0'\n",
    "\n",
    "for index, row in bikeownership.iterrows():\n",
    "    bikeownership.at[index, 'x'] = int(row['GITTER_1km'][9:13])\n",
    "    bikeownership.at[index, 'y'] = int(row['GITTER_1km'][4:8])\n",
    "    \n",
    "bikeownership['x'] = pd.to_numeric(bikeownership['x'])\n",
    "bikeownership['y'] = pd.to_numeric(bikeownership['y'])\n",
    "\n",
    "heatmap_data = bikeownership.pivot(index='y', columns='x', values='cbike_share')\n",
    "\n",
    "# Create the heatmap using imshow\n",
    "plt.rc('font', family='Arial', size=12)\n",
    "plt.imshow(heatmap_data, cmap='plasma', origin='lower', extent=[min(bikeownership['x']), max(bikeownership['x']), min(bikeownership['y']), max(bikeownership['y'])])\n",
    "plt.colorbar(label='slope')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "#plt.savefig(\"cbikeownership_NRW.svg\", format='svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8646fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map ebike \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#set values larger than 0.2 to 0.2.\n",
    "bikeownership['ebike_share'] = bikeownership['ebike_share'].clip(upper=0.2)\n",
    "\n",
    "bikeownership['x']='0'\n",
    "bikeownership['y']='0'\n",
    "\n",
    "for index, row in bikeownership.iterrows():\n",
    "    bikeownership.at[index, 'x'] = int(row['GITTER_1km'][9:13])\n",
    "    bikeownership.at[index, 'y'] = int(row['GITTER_1km'][4:8])\n",
    "    \n",
    "bikeownership['x'] = pd.to_numeric(bikeownership['x'])\n",
    "bikeownership['y'] = pd.to_numeric(bikeownership['y'])\n",
    "\n",
    "heatmap_data = bikeownership.pivot(index='y', columns='x', values='ebike_share')\n",
    "\n",
    "# Create the heatmap using imshow\n",
    "plt.rc('font', family='Arial', size=12)\n",
    "plt.imshow(heatmap_data, cmap='plasma', origin='lower', extent=[min(bikeownership['x']), max(bikeownership['x']), min(bikeownership['y']), max(bikeownership['y'])])\n",
    "plt.colorbar(label='e-bike ownership rate')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "#plt.savefig(\"ebikeownership_NRW.svg\", format='svg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
